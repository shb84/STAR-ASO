#!/usr/bin/python
"""
-----------------------------------------------------------------------------------------------------
TITLE: Optimiser for STAR-CCM+ ASO Framework
-----------------------------------------------------------------------------------------------------
DESCRIPTION: The objective of this script is to provide a linkage between the ASO framework
interacting with STAR-CCM+ and the Python based optimization algorithm. This script calls the ASO
framework, which runs the STAR-CCM+ simulation, & reads the output file generated by the framework.
This output file contains information about the objective function, constraint values and
gradients. The wrapper then calls the optimizer using this information, and edits the input file to
the framework with the updated design variable values.
-----------------------------------------------------------------------------------------------------
WRITTEN  BY: Jai Ahuja (Graduate Research Assistant - ASDL)
MODIFIED BY: Steven Berguin (Research Engineer II)
-----------------------------------------------------------------------------------------------------
LAST MODIFIED: 4th December 2017
-----------------------------------------------------------------------------------------------------
DEVELOPMENT NOTES:
  1) Assuming single objective function for now.
  2) h(x) = 0 and g(x) >= 0 are the assumed formats for the constraints, consistent with the package
  requirements. Therefore h(x) = Actual - Target and g(x) = Actual - Target.
-----------------------------------------------------------------------------------------------------
"""

import numpy as np
import os
import pandas as pd
from scipy.optimize import minimize
import subprocess
import argparse

# ----------------------------------------------------------------------------------------------------------------------
# CSV FILE INPUTS 
# ----------------------------------------------------------------------------------------------------------------------

# Read initial values contained in files
inputs = pd.read_csv("IndependentVariables.csv")
output = pd.read_csv("DependentVariables.csv")

# Read inputs
x_0 = np.reshape(inputs["X0"].values, (-1, 1))
x_min = np.reshape(inputs["Xmin"].values, (-1, 1))
x_max = np.reshape(inputs["Xmax"].values, (-1, 1))
typical_x = np.reshape(inputs["TypicalX"].values, (-1, 1))
n_var = x_0.size
var_bounds = np.concatenate((x_min, x_max), axis=1)

# Count number of objectives, equality constraints, inequality constraints
n_f = output["Type"].where(output["Type"] == "Objective").count()
n_h = output["Type"].where(output["Type"] == "Equality").count()
n_g = output["Type"].where(output["Type"] == "Inequality").count()

# Create masks for each function type
f_mask = output["Type"].where(output["Type"] == "Objective").notnull()
h_mask = output["Type"].where(output["Type"] == "Equality").notnull()
g_mask = output["Type"].where(output["Type"] == "Inequality").notnull()

# Get corresponding indices
f_indices = np.where(f_mask)[0]
h_indices = np.where(h_mask)[0]
g_indices = np.where(g_mask)[0]

# Obtain target values for the constraints
h_targets = ()
g_targets = ()
if n_h > 0:
    h_targets = np.reshape(output["Target"][h_mask].values, (-1, 1))
if n_g > 0:
    g_targets = np.reshape(output["Target"][g_mask].values, (-1, 1))

# ----------------------------------------------------------------------------------------------------------------------
# GLOBAL VARIABLES
# ----------------------------------------------------------------------------------------------------------------------

# Initialize global variables (used to keep track of optimizer history)
iteration = 0
if n_f > 0:
    f = [None]*n_f
    dfdx = np.zeros((n_f, n_var))
if n_g > 0:
    g = [None]*n_g
    dgdx = np.zeros((n_g, n_var))
if n_h > 0:
    h = [None]*n_h
    dhdx = np.zeros((n_h, n_var))

# ----------------------------------------------------------------------------------------------------------------------
# COMMAND LINE ARGUMENTS
# ----------------------------------------------------------------------------------------------------------------------

# Get command line arguments
parser = argparse.ArgumentParser(description='This program runs the specified Star-CCM+ simulation')

parser.add_argument('-hpc', action="store_true", dest="isCluster",
                    default=False,
                    help='True if program is running on a cluster')

parser.add_argument('-jar', action="store", dest="class_path", type=str,
                    default=None,
                    help='Path of the jar file containing the user-defined classes')

parser.add_argument('-macro', action="store", dest="macro", type=str,
                    default=os.getcwd(),
                    help='Path of the java macro')

parser.add_argument('-sim', action="store", dest="sim_file", type=str,
                    default=None,
                    help='Path of Star-CCM+ simulation file')

parser.add_argument('-N', action="store", dest="number_processors", type=str,
                    default="2",
                    help='Number of processors eg. $NPROCS')

parser.add_argument("-pwd", action="store", dest="work_dir", type=str,
                    default=os.getcwd(),
                    help='Present working directory eg. $PBS_O_WORKDIR')

parser.add_argument("-nodes", action="store", dest="machinefile", type=str,
                    default=None,
                    help='Cluster machine file eg. $PBS_NODEFILE')

parser.add_argument("-pod", action="store", dest="podkey", type=str,
                    default=None,
                    help='License power on demand key')

parser.add_argument("-lic", action="store", dest="licencepath", type=str,
                    default="1999@flex.cd-adapco.com",
                    help='License server')

parser.add_argument("-maxiter", action="store", dest="max_iter", type=str,
                    default="15",
                    help='Maximum number of optimizer iterations')

args = parser.parse_args()

# Initialize dictionary
star_flags = dict({"jar": args.class_path,
                   "sim": args.sim_file,
                   "np": args.number_processors,
                   "pod": args.podkey,
                   "lic": args.licencepath,
                   "macro": args.macro,
                   "hpc": args.isCluster,
                   "pwd": args.work_dir,
                   "nodes": args.machinefile,
                   "adjoint": False})

# ----------------------------------------------------------------------------------------------------------------------
# SUPPORT FUNCTIONS
# ----------------------------------------------------------------------------------------------------------------------

def call_starccmplus(adj_flag = False):
    """
    DESCRIPTION
    Calls STAR-CCM+ and evaluates the current design x. This is accomplished by
    a java {macro}, which has logic to read/write values contained in the CSV
    files (IndependentVariables.csv and DependentVariables.csv) that were just
    updated in the parent function calling this one.

    ARGUMENTS
    :param adj_flag: a flag to turn adjoint solver off during line search (save time)

    OUTPUTS
    :return: none (output values written to CSV file DependentVariables.csv)
    """
    star_flags["adjoint"] = adj_flag
    if star_flags["hpc"]:  # run on cluster
        sys_call = 'starccm+ ' \
                   '-podkey {pod} ' \
                   '-licpath {lic} ' \
                   '-mpi intel ' \
                   '-power ' \
                   '-np {np} ' \
                   '-classpath {jar} ' \
                   '-machinefile {nodes} ' \
                   '-jvmargs -Dadj_flag={adjoint} ' \
                   '-batch {macro} {sim} ' \
                   '> star.log'.format(**star_flags)
    else:  # run on desktop
        sys_call = 'starccm+ ' \
                   '-cpubind ' \
                   '-rsh ssh ' \
                   '-podkey {pod} ' \
                   '-licpath {lic} ' \
                   '-power ' \
                   '-np {np} ' \
                   '-classpath {jar} ' \
                   '-jvmargs -Dadj_flag={adjoint} ' \
                   '-batch {macro} {sim} ' \
                   '> star.log'.format(**star_flags)
    subprocess.run(sys_call, shell=True)\


def obj_func(x):
    """
    DESCRIPTION
    Evaluates the objective function by updating the CSV file with the
    current design value and calling STAR-CCM+

    ARGUMENTS
    :param x: current design to evaluate (array of values)

    OUTPUTS
    :return y: value of objective function evaluated at x (scalar)
    """
    global f
    inputs["X"] = x
    inputs.to_csv("IndependentVariables.csv", index=False)
    call_starccmplus(adj_flag=False)
    output = pd.read_csv("DependentVariables.csv")
    f = np.reshape(output["F"][f_mask].values, (-1, 1))
    return f.ravel()


def obj_func_jac(x):
    """
    DESCRIPTION
    Evaluates the objective function gradient by updating the CSV file
    with the current design value and calling STAR-CCM+

    ARGUMENTS
    :param x: current design to be evaluated

    OUTPUTS
    :return dfdx: gradient of f with respect to x
    """
    inputs["X"] = x
    inputs.to_csv("IndependentVariables.csv", index=False)
    call_starccmplus(adj_flag=True)
    output = pd.read_csv("DependentVariables.csv")
    for i in range(0, n_f):
        for j in range(0, n_var):
            dfdx[i, j] = output["dFdx" + str(j + 1)][f_indices]  # +1 b/c assumes x starts at x1, x2, ...
    return dfdx.ravel()


def eq_const(x):
    """
    DESCRIPTION
    Computes equality constraints of the form h(x) = 0. This is accomplished
    by reading the DependentVariables.csv file which contains force coefficient
    values and subtracting the target, e.g. h(x) = CL(x) - CL_target

    ARGUMENTS
    :param x: current design to be evaluated. Note that x is not used because
    STAR-CCM+ does not need to be re-evaluated. Force coefficient values were
    already computed during the call to obj_func(x); hence, all we need to do
    here is read the result. However, x must still be passed as an argument
    because that's how the optimizer works.

    OUTPUTS
    :return: h(x)
    """
    global h
    if n_h > 0:
        output = pd.read_csv("DependentVariables.csv")
        h = np.reshape(output["F"][h_mask].values, (-1, 1)) - h_targets
        return h.ravel()
    else:
        print("No equality constraints to evaluate. eq_const(x) should not be called.")
        assert(n_h > 0)


def ineq_const(x):
    """
    DESCRIPTION
    Computes inequality constraints of the form g(x) >= 0. This is accomplished
    reading the DependentVariables.csv file which contains force coefficient
    values and subtracting the target, e.g. g(x) = CL(x) - CL_target

    ARGUMENTS
    :param x: current design to be evaluated. Note that x is not used because
    STAR-CCM+ does not need to be re-evaluated. Force coefficient values were
    already computed during the call to obj_func(x); hence, all we need to do
    here is read the result. However, x must still be passed as an argument
    because that's how the optimizer works.

    OUTPUTS
    :return: g(x)
    """
    global g
    if n_g > 0:
        output = pd.read_csv("DependentVariables.csv")
        g = np.reshape(output["F"][g_mask].values, (-1, 1)) - g_targets
        return g.ravel()
    else:
        print("No inequality constraints to evaluate. ineq_const(x) should not be called.")
        assert(n_g > 0)


def eq_const_jac(x):
    """
    DESCRIPTION
    Computes equality constraints gradient. This is accomplished by reading the
    DependentVariables.csv file which contains partial derivative values.

    ARGUMENTS
    :param x: current design to be evaluated. Note that x is not used because
    STAR-CCM+ does not need to be re-evaluated. Force coefficient values were
    already computed during the call to obj_func(x); hence, all we need to do
    here is read the result. However, x must still be passed as an argument
    because that's how the optimizer works.

    OUTPUTS
    :return: jacobian of h
    """
    if n_h > 0:
        output = pd.read_csv("DependentVariables.csv")
        for i in range(0, n_h):
            for j in range(0, n_var):
                dhdx[i, j] = output["dFdx" + str(j + 1)][h_indices]  # +1 b/c assumes x starts at x1, x2, ...
        return dhdx.ravel()
    else:
        print("No equality constraints to evaluate. eq_const_jac(x) should not be called.")
        assert(n_h > 0)

def ineq_const_jac(x):
    """
    DESCRIPTION
    Computes inequality constraints gradient. This is accomplished by reading the
    DependentVariables.csv file which contains partial derivative values.

    ARGUMENTS
    :param x: current design to be evaluated. Note that x is not used because
    STAR-CCM+ does not need to be re-evaluated. Force coefficient values were
    already computed during the call to obj_func(x); hence, all we need to do
    here is read the result. However, x must still be passed as an argument
    because that's how the optimizer works.

    OUTPUTS
    :return: jacobian of g
    """
    if n_g > 0:
        output = pd.read_csv("DependentVariables.csv")
        for i in range(0, n_g):
            for j in range(0, n_var):
                dgdx[i, j] = output["dFdx" + str(j + 1)][g_indices]  # +1 b/c assumes x starts at x1, x2, ...
        return dgdx.ravel()
    else:
        print("No inequality constraints to evaluate. ineq_const_jac(x) should not be called.")
        assert (n_g > 0)


def printarray(array):
    """
    DESCRIPTION
    Prints an array on one line. Each element is separated by a delimiter.

    ARGUMENTS
    :param array: the array you want to print
    """
    n = len(array)
    for i in range(0, n):
        print(array[i], end=",")


def callback(x):
    """
    DESCRIPTION
    Optimiser callback function used to print iteration history. Unfortunately,
    the optimizer we're using does not seem to have any options to print the
    iteration history, so this is a make shift function to do so. Feel free to
    improve it.

    ARGUMENTS
    :param x: dummy input (only here because that format is needed by the optimizer)
    """
    global iteration
    global f
    global g
    global h
    if iteration == 0:
        print('N', end=',')
        if n_f > 0:
            for i in range(0, n_f):
                print('F%i' % i, end=',')
        if n_g > 0:
            for i in range(0, n_g):
                print('G%i' % i, end=',')
        if n_h > 0:
            for i in range(0, n_h):
                print('H%i' % i, end=',')
        print()
    print(iteration, end=',')
    if n_f > 0:
        printarray(f)
    if n_g > 0:
        printarray(g)
    if n_h > 0:
        printarray(h)
    iteration = iteration + 1
    print()


# ----------------------------------------------------------------------------------------------------------------------
# MAIN PROGRAM
# ----------------------------------------------------------------------------------------------------------------------

# Compile list of constraints for the optimizer
if n_h == 0 and n_g > 0:
    cons = ({'type': 'ineq', 'fun': lambda x: ineq_const(x), 'jac': lambda x: ineq_const_jac(x)})
elif n_h > 0 and n_g == 0:
    cons = ({'type': 'eq', 'fun': lambda x: eq_const(x), 'jac': lambda x: eq_const_jac(x)})
elif n_h > 0 and n_g > 0:
    cons = ({'type': 'ineq', 'fun': lambda x: ineq_const(x), 'jac': lambda x: ineq_const_jac(x)},
            {'type': 'eq', 'fun': lambda x: eq_const(x), 'jac': lambda x: eq_const_jac(x)})
else:
    cons = ()

# Optimiser Call
print('Running optimization...')
best = minimize(obj_func,
                x_0,
                jac=obj_func_jac,
                constraints=cons,
                method='SLSQP',
                callback=callback,
                options={'disp': True, 'maxiter': args.max_iter, 'ftol': 1e-06},
                bounds=var_bounds)
print()
print('Best Design:')
print(best)